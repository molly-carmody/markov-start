In this question, you will examine how the k-value/order of the model, the length of the training text, and the number of characters generated affect the runtime for BruteMarkov. To do that, determine how long it takes for each of the following Markov trials to run:

alice.txt, k = 1, 200 characters max: 0.119

alice.txt, k = 1, 400 characters max: 0.081

alice.txt, k = 1, 800 characters max: 0.077

alice.txt, k = 5, 200 characters max: 0.273

alice.txt, k = 5, 400 characters max: 0.271

alice.txt, k = 5, 800 characters max: 0.283

alice.txt, k = 10, 200 characters max: 0.644

alice.txt, k = 10, 400 characters max: 0.629

alice.txt, k = 10, 800 characters max: 0.660

hawthorne.txt, k = 1, 200 characters max: 0.118

hawthorne.txt, k = 1, 400 characters max: 0.105

hawthorne.txt, k = 1, 800 characters max: 0.101




Based on these results, what is the relationship between the runtime and the length of the training text, the k-value, and the max characters generated? How long do you think it will take to generate 1600 random characters using an order-5 Markov model when the The Complete Works of William Shakespeare is used as the training text — our online copy of this text contains roughly 5.5 million characters. Justify your answer — don’t test empirically, use reasoning.
-- just for getRnadom

Provide timings using your Efficient model for both creating the map and generating 200, 400, 800, and 1600 character random texts with an order-5 Model and alice.txt. Provide some explanation for the timings you observe.
- for both creating map and generating text
- HAVE to get justification  --> this is bigger than this

Provide timings for the EfficientWordMarkov with different hashcode methods. Time the method you are given and compare the results that you achieve with the better hashcode method that you developed.
-- time give (liek hash = 32) adn how that compare to one you made 

Using a k of your choice and clinton-convention.txt as the training text, if we do not set a maximum number of characters generated (you can effectively do this by having maxLetters be a large number, e.g. 1000 times the size of the training text) what is the average number of characters generated by our Markov text generator?
-- you pick teh k, how many characters do you egenratea from the txt.  --> run a bunch of times and get na everage
-- tell what value of k is 


PARTB
hashmap vs. treemap
-- eveyr time you call a treemap, its alling your compare to method
every time you call a hashmap its calling your hashcode method
-- dont have to turn in a graph (good if put in reposiitroy tho)
--this one about WORDGRAM

